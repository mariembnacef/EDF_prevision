#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Pipeline de traitement des donn√©es de consommation √©lectrique et mod√©lisation avec Prefect
Ce script orchestre le processus complet en trois √©tapes avec Prefect:
1. T√©l√©chargement des fichiers de donn√©es √† partir de RTE
2. Pr√©paration des donn√©es
3. Entra√Ænement et √©valuation du mod√®le
"""

import os
import sys
import time
from datetime import datetime
from typing import Dict, Tuple, Any

import mlflow
import prefect
from prefect import task, flow
from prefect.context import get_run_context

# Import des modules n√©cessaires
# Ces importations seront tent√©es mais le code continuera m√™me si certains modules manquent
train_test = None
download_file = None
processing_data = None  # Chang√© de prepare_data √† processing_data

try:
    import train_test
except ImportError:
    print("Module train_test non trouv√©. Certaines fonctionnalit√©s seront limit√©es.")

try:
    import download_file
except ImportError:
    print("Module download_file non trouv√©. Le t√©l√©chargement sera d√©sactiv√©.")

try:
    import processing_data  # Chang√© de preparer_donnees √† processing_data
except ImportError:
    print("Module processing_data non trouv√©. Le pr√©traitement int√©gr√© sera utilis√© si disponible.")


@task(name="Configuration des chemins", description="D√©finit les chemins utilis√©s dans le pipeline")
def setup_directories() -> Dict[str, str]:
    """
    Configuration des r√©pertoires pour le pipeline.
    
    Returns:
        Dict[str, str]: Dictionnaire contenant tous les chemins n√©cessaires
    """
    # D√©finition des chemins
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base_dir, "data")
    raw_dir = os.path.join(data_dir, "raw")
    extracted_dir = os.path.join(base_dir, "rte_extracted")
    annuel_dir = os.path.join(extracted_dir, "annuel")
    calendar_dir = os.path.join(extracted_dir, "calendar")
    processed_dir = os.path.join(data_dir, "processed")
    processed_data_path = os.path.join(processed_dir, "df_filtre.csv")
    model_dir = os.path.join(base_dir, "models")
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_path = os.path.join(model_dir, f"xgboost_conso_model_{timestamp}.pkl")
    
    # Cr√©ation des r√©pertoires
    for path in [raw_dir, extracted_dir, annuel_dir, calendar_dir, processed_dir, model_dir]:
        os.makedirs(path, exist_ok=True)
    
    return {
        "base_dir": base_dir,
        "data_dir": data_dir,
        "raw_dir": raw_dir,
        "extracted_dir": extracted_dir,
        "annuel_dir": annuel_dir,
        "calendar_dir": calendar_dir,
        "processed_data_path": processed_data_path,
        "model_dir": model_dir,
        "model_path": model_path,
        "timestamp": timestamp
    }


@task(name="Configuration MLflow", description="Configure MLflow pour le tracking des exp√©riences")
def setup_mlflow() -> str:
    """
    Configure MLflow pour le suivi des exp√©riences.
    
    Returns:
        str: URI de tracking MLflow
    """
    tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "http://localhost:5000")
    mlflow.set_tracking_uri(tracking_uri)
    mlflow.set_experiment("conso-electrique-xgboost")
    return tracking_uri


@task(name="T√©l√©chargement des donn√©es", 
      description="T√©l√©chargement des fichiers depuis RTE",
      retries=2,
      retry_delay_seconds=30)
def download_data(paths: Dict[str, str]) -> Dict[str, str]:
    """
    T√©l√©chargement des fichiers de donn√©es depuis RTE.
    
    Args:
        paths (Dict[str, str]): Dictionnaire des chemins
        
    Returns:
        Dict[str, str]: Statut du t√©l√©chargement et m√©tadonn√©es
    """
    logger = prefect.get_run_logger()
    logger.info("üîÑ T√©l√©chargement des fichiers depuis RTE...")
    
    try:
        download_file.main()
        logger.info("‚úÖ T√©l√©chargement termin√© avec succ√®s")
        return {"status": "success", "message": "T√©l√©chargement r√©ussi"}
    except Exception as e:
        if download_file is None:
            logger.error("Module download_file non disponible")
            return {"status": "failed", "error": "Module manquant", "message": "Module download_file non disponible"}
        else:
            logger.error(f"‚ùå ERREUR lors du t√©l√©chargement: {str(e)}")
            logger.warning("‚ö†Ô∏è Continuation avec les donn√©es d√©j√† pr√©sentes...")
            return {"status": "failed", "error": str(e), "message": "√âchec du t√©l√©chargement"}


@task(name="Pr√©traitement des donn√©es", 
      description="Pr√©paration et nettoyage des donn√©es",
      retries=1)
def process_data(paths: Dict[str, str], verbose: bool = True) -> Dict[str, str]:
    """
    Pr√©traitement des donn√©es t√©l√©charg√©es.
    
    Args:
        paths (Dict[str, str]): Dictionnaire des chemins
        verbose (bool): Activation des logs d√©taill√©s
        
    Returns:
        Dict[str, str]: Statut du pr√©traitement et m√©tadonn√©es
    """
    logger = prefect.get_run_logger()
    logger.info("üîÑ Pr√©traitement des donn√©es...")
    
    try:
        # Modifi√© pour utiliser processing_data.process_consumption_data
        if processing_data is not None:
            # Appel de process_consumption_data avec les bons param√®tres
            processing_data.process_consumption_data(
                paths["annuel_dir"], 
                paths["calendar_dir"], 
                paths["processed_data_path"]
            )
            logger.info("‚úÖ Pr√©traitement des donn√©es termin√© avec succ√®s")
            return {"status": "success", "message": "Pr√©traitement r√©ussi", "output_path": paths["processed_data_path"]}
        else:
            # Essaie d'utiliser le pr√©traitement int√©gr√© dans train_test si processing_data n'est pas disponible
            logger.info("Module processing_data non disponible, v√©rification si le pr√©traitement est int√©gr√© dans train_test...")
            if hasattr(train_test, 'prepare_data') or hasattr(train_test, 'preprocess_data'):
                preprocess_fn = getattr(train_test, 'prepare_data', None) or getattr(train_test, 'preprocess_data', None)
                preprocess_fn(paths["raw_dir"], paths["processed_data_path"], verbose=verbose)
                logger.info("‚úÖ Pr√©traitement int√©gr√© termin√© avec succ√®s")
                return {"status": "success", "message": "Pr√©traitement int√©gr√© r√©ussi", "output_path": paths["processed_data_path"]}
            else:
                logger.warning("Aucune fonction de pr√©traitement disponible. V√©rifiez les donn√©es pr√©trait√©es existantes.")
                return {"status": "skipped", "message": "Aucun pr√©traitement disponible"}
    except Exception as e:
        logger.error(f"‚ùå ERREUR lors du pr√©traitement: {str(e)}")
        logger.warning("‚ö†Ô∏è Continuation avec les donn√©es pr√©trait√©es existantes...")
        return {"status": "failed", "error": str(e), "message": "√âchec du pr√©traitement"}


@task(name="Entra√Ænement et √©valuation", 
      description="Entra√Ænement du mod√®le XGBoost et √©valuation des performances")
def train_and_evaluate(
    paths: Dict[str, str], 
    verbose: bool = True, 
    mode_rapide: bool = True
) -> Dict[str, Any]:
    """
    Entra√Ænement et √©valuation du mod√®le.
    
    Args:
        paths (Dict[str, str]): Dictionnaire des chemins
        verbose (bool): Activation des logs d√©taill√©s
        mode_rapide (bool): Utilisation du mode d'entra√Ænement rapide
        
    Returns:
        Dict[str, Any]: R√©sultats de l'entra√Ænement et m√©triques
    """
    logger = prefect.get_run_logger()
    logger.info("üîÑ Entra√Ænement et √©valuation du mod√®le...")
    
    try:
        if train_test is None:
            logger.error("Module train_test non disponible, impossible de poursuivre l'entra√Ænement")
            return {"status": "failed", "error": "Module manquant", "message": "Module train_test requis non disponible"}
            
        best_model, resultats = train_test.executer_pipeline_complete(
            paths["processed_data_path"],
            paths["model_path"],
            verbose=verbose,
            mode_rapide=mode_rapide
        )
        
        logger.info(f"‚úÖ Entra√Ænement termin√© avec succ√®s")
        logger.info(f"üìä R¬≤ validation: {resultats['r2_val']:.4f}, RMSE validation: {resultats['rmse_val']:.2f}")
        
        # Ajout des m√©triques pour Prefect
        return {
            "status": "success",
            "model_path": paths["model_path"],
            "rmse_val": resultats.get('rmse_val'),
            "r2_val": resultats.get('r2_val'),
            "overfitting": resultats.get('overfitting', False)
        }
    except Exception as e:
        logger.error(f"‚ùå ERREUR lors de l'entra√Ænement: {str(e)}")
        return {"status": "failed", "error": str(e)}


@flow(name="Pipeline Consommation √âlectrique",
      description="Pipeline compl√®te d'analyse de la consommation √©lectrique")
def pipeline_consommation_electrique(
    do_download: bool = True,
    do_processing: bool = True,
    verbose: bool = True,
    mode_rapide: bool = True
) -> Dict[str, Any]:
    """
    Flow principal Prefect qui orchestre le pipeline complet.
    
    Args:
        do_download (bool): Activer le t√©l√©chargement des donn√©es
        do_processing (bool): Activer le pr√©traitement des donn√©es
        verbose (bool): Activer les logs d√©taill√©s
        mode_rapide (bool): Utiliser le mode d'entra√Ænement rapide
        
    Returns:
        Dict[str, Any]: R√©sultats globaux du pipeline
    """
    logger = prefect.get_run_logger()
    start_time = time.time()
    
    # R√©cup√©ration du contexte du flow
    try:
        context = get_run_context()
        run_id = context.flow_run.id if hasattr(context, 'flow_run') else "unknown"
    except Exception:
        run_id = "local-run"
    
    # 0. Configuration des chemins et MLflow
    paths = setup_directories()
    tracking_uri = setup_mlflow()
    
    # D√©marrage de la run MLflow
    with mlflow.start_run(run_name=f"xgboost_{paths['timestamp']}"):
        # Log des param√®tres initiaux
        mlflow.log_params({
            "timestamp": paths["timestamp"],
            "do_download": do_download,
            "do_processing": do_processing,
            "verbose": verbose,
            "mode_rapide": mode_rapide,
            "prefect_run_id": run_id
        })
        
        # 1. T√©l√©chargement
        download_result = {"status": "skipped"}
        if do_download:
            download_result = download_data(paths)
            mlflow.log_param("download_status", download_result["status"])
            if download_result["status"] == "failed":
                mlflow.log_param("download_error", download_result.get("error", "unknown"))
        else:
            logger.info("üîÑ T√©l√©chargement ignor√© (donn√©es existantes)")
            mlflow.log_param("download_status", "skipped")
        
        # 2. Pr√©traitement
        processing_result = {"status": "skipped"}
        if do_processing:
            processing_result = process_data(paths, verbose)
            mlflow.log_param("processing_status", processing_result["status"])
            if processing_result["status"] == "failed":
                mlflow.log_param("processing_error", processing_result.get("error", "unknown"))
        else:
            logger.info("üîÑ Pr√©traitement ignor√© (donn√©es pr√©trait√©es existantes)")
            mlflow.log_param("processing_status", "skipped")
        
        # 3. Entra√Ænement et √©valuation
        training_result = train_and_evaluate(paths, verbose, mode_rapide)
        
        if training_result["status"] == "success":
            # Log des m√©triques dans MLflow
            mlflow.log_metrics({
                "final_rmse_val": training_result["rmse_val"],
                "final_r2_val": training_result["r2_val"]
            })
            mlflow.log_param("overfitting_detected", training_result.get("overfitting", False))
            
            # Enregistrement du chemin du mod√®le
            mlflow.log_param("model_path", training_result["model_path"])
        else:
            mlflow.log_param("training_error", training_result.get("error", "unknown"))
        
        # Dur√©e totale
        total_time = time.time() - start_time
        mlflow.log_metric("pipeline_total_time_seconds", total_time)
        
        logger.info(f"\n‚ú® Pipeline termin√©e en {total_time:.2f}s ({total_time/60:.2f}min)")
        
        if training_result["status"] == "success":
            logger.info(f"üìä R¬≤ validation: {training_result['r2_val']:.4f}, RMSE validation: {training_result['rmse_val']:.2f}")
            logger.info(f"üíæ Mod√®le final sauvegard√© sous: {paths['model_path']}")
        
        # R√©sultat global du pipeline
        return {
            "success": training_result["status"] == "success",
            "download": download_result,
            "processing": processing_result,
            "training": training_result,
            "total_time": total_time,
            "paths": paths
        }


if __name__ == "__main__":
    # Ex√©cution du flow Prefect
    pipeline_consommation_electrique()